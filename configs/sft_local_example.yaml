training:
  output_dir: runs/sft/qwen3-0.6b/local-smoke
  model_name_or_path: Qwen/Qwen3-0.6B
  seed: 42
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 1
  num_train_epochs: 2
  warmup_ratio: 0.03
  gradient_checkpointing: true
  logging_steps: 10
  log_with_tensorboard: true
  save_steps: 100

dataset:
  name_or_path: data/train.jsonl
  split: train

lora:
  r: 8
  alpha: 16
  target_modules: all-linear

optimizer:
  learning_rate: 0.0001
  weight_decay: 0.01
